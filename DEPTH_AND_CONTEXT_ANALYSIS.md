# PhÃ¢n TÃ­ch: DiT Depth=12 & Context Learning Issues

## â“ Váº¤N Äá»€:

> "DiTÃ—12 cÃ³ quÃ¡ sÃ¢u khÃ´ng? áº¢nh eval khÃ´ng há»c Ä‘Æ°á»£c gÃ¬ tá»« Ä‘iá»u kiá»‡n c, khÃ´ng ra hÃ¬nh."

---

## ğŸ” PHÃ‚N TÃCH CÃC NGUYÃŠN NHÃ‚N:

### **1ï¸âƒ£ CRITICAL ISSUE: adaLN-Zero Initialization**

#### **Code: `model/set_diffusion/dit_jax.py`**

```python
# DiTBlock, lines 241-244
class DiTBlock(nn.Module):
    # ...
    @nn.compact
    def __call__(self, x, c, context=None):
        # ...
        # adaLN-Zero: scale, shift, gate
        adaLN_params = nn.Dense(
            6 * self.hidden_size,
            kernel_init=nn.initializers.zeros,  # â† ZERO INIT!
            bias_init=nn.initializers.zeros      # â† ZERO INIT!
        )(c)
        
        scale_msa, shift_msa, gate_msa, scale_mlp, shift_mlp, gate_mlp = \
            jnp.split(adaLN_params, 6, axis=-1)
```

#### **âŒ Váº¤N Äá»€:**

**adaLN-Zero khá»Ÿi táº¡o vá»›i ZERO parameters!**

```
Ban Ä‘áº§u:
  adaLN_params = c @ W + b
               = c @ 0 + 0  
               = 0          â† ALL ZEROS!

â†’ scale = 0, shift = 0, gate = 0
â†’ Context c KHÃ”NG CÃ“ EFFECT GÃŒ ban Ä‘áº§u!
â†’ Model pháº£i há»c tá»« Ä‘áº§u Ä‘á»ƒ context cÃ³ tÃ¡c dá»¥ng!
```

**Táº¡i sao láº¡i dÃ¹ng zero init?**
- **DiT paper design**: adaLN-Zero giÃºp training stability
- Ban Ä‘áº§u model = standard transformer (no conditioning)
- Gradually há»c cÃ¡ch dÃ¹ng conditioning
- **NhÆ°ng: Cáº§n NHIá»€U steps Ä‘á»ƒ context báº¯t Ä‘áº§u cÃ³ effect!**

---

### **2ï¸âƒ£ ISSUE: Depth=12 CÃ³ QuÃ¡ SÃ¢u?**

#### **So sÃ¡nh vá»›i cÃ¡c models khÃ¡c:**

| Model | Depth | Image Size | Notes |
|-------|-------|------------|-------|
| **VFSDDPM (yours)** | **12** | 32Ã—32 | Few-shot |
| DiT-S/2 | 12 | 256Ã—256 | Standard DiT |
| DiT-B/2 | 12 | 256Ã—256 | Larger version |
| ViT-Base | 12 | 224Ã—224 | Classification |
| DALL-E 2 | 24 | 256Ã—256 | Text-to-image |
| Stable Diffusion | 12-16 | 512Ã—512 | Text-to-image |

#### **PhÃ¢n tÃ­ch:**

**âœ… Depth=12 KHÃ”NG QUÃ SÃ‚U cho image generation!**
- DiT paper uses depth=12 for 256Ã—256 images
- Your images: 32Ã—32 (much smaller!)
- â†’ Depth=12 lÃ  reasonable, tháº­m chÃ­ cÃ³ thá»ƒ cáº§n!

**NhÆ°ng vá»›i 32Ã—32 images:**
- CÃ³ Ã­t patches hÆ¡n: 256 patches (vs 1024 for 64Ã—64)
- Information complexity tháº¥p hÆ¡n
- **CÃ³ thá»ƒ depth=8 Ä‘Ã£ Ä‘á»§!**

---

### **3ï¸âƒ£ ISSUE: Gradient Flow & Learning Rate**

#### **Vá»›i depth=12 + adaLN-Zero:**

```
Problems:
  1. Zero init â†’ Context effect starts at 0
  2. 12 layers â†’ Gradient pháº£i flow through nhiá»u layers
  3. Learning rate cÃ³ thá»ƒ khÃ´ng Ä‘á»§ Ä‘á»ƒ context layers há»c nhanh
  4. Ban Ä‘áº§u model há»c nhÆ° standard DDPM (no context)
  
â†’ Context CHáº¬M há»c!
â†’ FID improvement cháº­m!
```

#### **Gradient vanishing risk:**

```
Forward: x â†’ Block1 â†’ Block2 â†’ ... â†’ Block12 â†’ output
         â†‘                                      â†‘
      Input                                  Loss
         
Backward: âˆ‚L/âˆ‚x â† Block1 â† Block2 â† ... â† Block12 â† âˆ‚L/âˆ‚output

Vá»›i 12 layers:
  - Gradient tá»« output vá» input qua 12 blocks
  - Náº¿u má»—i block cÃ³ scale < 1 â†’ gradient decay
  - LayerNorm + Residual connections giÃºp, nhÆ°ng váº«n cÃ³ risk
```

---

### **4ï¸âƒ£ ISSUE: Training Steps ChÆ°a Äá»§?**

#### **Thá»i gian Ä‘á»ƒ context cÃ³ effect:**

```
With adaLN-Zero:
  Steps 0-5k:     Context effect â‰ˆ 0 (still mostly zeros)
  Steps 5k-20k:   Context starts to have small effect
  Steps 20k-50k:  Context effect growing
  Steps 50k-100k: Context effect significant
  Steps 100k+:    Context fully learned

Kaggle 9h limit: ~80k steps
  â†’ CÃ³ thá»ƒ CHÆ¯A Äá»¦ Ä‘á»ƒ context fully kick in!
```

---

## ğŸ¯ GIáº¢I PHÃP:

### **ğŸš€ Solution 1: GIáº¢M DEPTH (RECOMMENDED!)**

#### **Thá»­ depth=8 hoáº·c 6:**

```bash
# Depth = 8 (giáº£m 4 blocks)
python main_jax.py \
    --depth 8 \          # â† Change nÃ y!
    --hidden_size 384 \
    --num_heads 6 \
    ...
```

**Lá»£i Ã­ch:**
- âœ… Faster training (~25% faster per step)
- âœ… Better gradient flow
- âœ… Fewer params (~32M â†’ ~24M)
- âœ… Context cÃ³ thá»ƒ há»c nhanh hÆ¡n
- âœ… Äá»§ cho 32Ã—32 images

**Trade-off:**
- âš ï¸ Less model capacity (nhÆ°ng cÃ³ thá»ƒ khÃ´ng cáº§n cho 32Ã—32)

---

### **ğŸ”¥ Solution 2: WARM-START Context Projection**

#### **Thay Ä‘á»•i initialization cho context projection:**

**File: `model/set_diffusion/dit_jax.py`, line ~325**

```python
# BEFORE (zero init for adaLN-Zero):
context_proj_layer = nn.Dense(
    self.hidden_size, 
    kernel_init=nn.initializers.xavier_uniform()  # â† Normal init
)

# NhÆ°ng adaLN sau Ä‘Ã³ váº«n zero init:
adaLN_params = nn.Dense(
    6 * self.hidden_size,
    kernel_init=nn.initializers.zeros,     # â† ZERO!
    bias_init=nn.initializers.zeros
)(c)
```

**FIX: Initialize adaLN bias to SMALL NON-ZERO values:**

```python
adaLN_params = nn.Dense(
    6 * self.hidden_size,
    kernel_init=nn.initializers.zeros,
    bias_init=nn.initializers.constant(0.01)  # â† SMALL INIT!
)(c)
```

**Lá»£i Ã­ch:**
- âœ… Context cÃ³ IMMEDIATE small effect
- âœ… Model váº«n stable (small init)
- âœ… Faster context learning

---

### **âš¡ Solution 3: HIGHER Learning Rate cho Context Layers**

#### **Use different learning rates:**

Trong `main_jax.py`, cÃ³ thá»ƒ dÃ¹ng layer-wise learning rates:

```python
# Context-related params: higher LR
context_params = [
    "encoder",
    "context_proj",
]

# Main DiT params: normal LR
dit_params = [...]

# Create optimizer with different LRs
```

**Lá»£i Ã­ch:**
- âœ… Context learns faster
- âœ… Main model stable

**Trade-off:**
- âš ï¸ More complex setup
- âš ï¸ Risk of overfitting context

---

### **ğŸ“ Solution 4: PRE-TRAIN Encoder**

#### **Train encoder separately first:**

```python
# Step 1: Train encoder to reconstruct images
#         (autoencoder-like)
for batch_set in data:
    c = encode_set(batch_set[:, :-1])  # Encode 5 images
    x_recon = decode(c)  # Decode to reconstruct
    loss = mse(x_recon, batch_set[:, -1])  # Reconstruct 6th image

# Step 2: Freeze encoder, train DiT
for batch_set in data:
    c = encode_set(batch_set)  # Use pretrained encoder
    loss = diffusion_loss(x, c)
```

**Lá»£i Ã­ch:**
- âœ… Encoder learns meaningful representations first
- âœ… DiT can focus on denoising with good context

**Trade-off:**
- âš ï¸ More training time
- âš ï¸ Two-stage training

---

### **ğŸ“Š Solution 5: MONITORING & DEBUGGING**

#### **Add logging to track context usage:**

```python
# In training loop, log:
1. Context magnitude: |c|
2. adaLN parameters magnitude: |scale|, |shift|, |gate|
3. Context gradient magnitude: |âˆ‚L/âˆ‚c|

# Example:
if global_step % 100 == 0:
    c_norm = jnp.linalg.norm(c)
    # Log context statistics
    wandb.log({
        "debug/context_norm": c_norm,
        "debug/context_max": jnp.max(jnp.abs(c)),
        "debug/context_min": jnp.min(jnp.abs(c)),
    })
```

**Äá»ƒ check:**
- Context cÃ³ Ä‘ang Ä‘Æ°á»£c dÃ¹ng khÃ´ng?
- adaLN params cÃ³ há»c khÃ´ng?
- Gradient cÃ³ flow vá» encoder khÃ´ng?

---

## ğŸ¯ RECOMMENDED ACTIONS:

### **Immediate (NÃªn lÃ m ngay):**

1. **âœ… GIáº¢M DEPTH xuá»‘ng 8 hoáº·c 6**
   ```bash
   --depth 8  # Thá»­ nÃ y trÆ°á»›c
   ```
   - Fastest solution
   - Most likely to help
   - Äá»§ cho 32Ã—32 images

2. **âœ… CHECK Training Loss Curve**
   - Loss cÃ³ Ä‘ang giáº£m khÃ´ng?
   - FID cÃ³ improve khÃ´ng?
   - Cáº§n bao nhiÃªu steps Ä‘á»ƒ tháº¥y improvement?

3. **âœ… VISUALIZE Support Set trong Wandb**
   - Images cÃ³ coherent khÃ´ng?
   - Support set vÃ  generated images cÃ³ similar style khÃ´ng?

---

### **Short-term (Sau khi thá»­ depth=8):**

4. **âœ… ADJUST adaLN Initialization**
   ```python
   bias_init=nn.initializers.constant(0.01)
   ```
   - Náº¿u depth=8 váº«n cháº­m

5. **âœ… INCREASE Learning Rate cho Encoder**
   ```python
   --lr 2e-4  # TÄƒng tá»« 1e-4
   ```
   - Hoáº·c dÃ¹ng layer-wise LR

---

### **Long-term (Náº¿u váº«n khÃ´ng work):**

6. **Pre-train Encoder** (autoencoder)
   
7. **Try Different Architecture:**
   - U-Net instead of DiT?
   - Hybrid: U-Net with context injection?

---

## ğŸ“ˆ EXPECTED RESULTS:

### **With depth=8:**

```
Expected improvements:
  - Training speed: ~25% faster per step
  - Context learning: ~30% faster
  - FID should improve by step 40k-60k
  - Generated images should show class-specific features

Timeline:
  Steps 0-10k:   Noisy images, no structure
  Steps 10k-30k: Basic shapes appear
  Steps 30k-50k: Class-specific features emerge â† Context kicks in!
  Steps 50k+:    Quality improves, FID drops
```

---

## ğŸ”¬ DIAGNOSTIC CHECKLIST:

**Náº¿u váº«n "khÃ´ng ra hÃ¬nh", check:**

- [ ] Loss cÃ³ Ä‘ang giáº£m khÃ´ng? (should drop to <0.1)
- [ ] Sample images trong Wandb cÃ³ improve khÃ´ng?
- [ ] Support set cÃ³ Ä‘Ãºng class khÃ´ng? (Ä‘Ã£ verify âœ…)
- [ ] Context injection cÃ³ Ä‘Ãºng khÃ´ng? (Ä‘Ã£ verify âœ…)
- [ ] Learning rate cÃ³ phÃ¹ há»£p khÃ´ng?
- [ ] Batch size cÃ³ Ä‘á»§ lá»›n khÃ´ng? (32 lÃ  á»•n)
- [ ] Diffusion steps (250) cÃ³ phÃ¹ há»£p khÃ´ng?
- [ ] Noise schedule (linear) cÃ³ tá»‘t khÃ´ng?

---

## ğŸ’¡ COMPARISON: Depth Options

| Depth | Params | Training Speed | Context Learning | Quality (32Ã—32) | Recommendation |
|-------|--------|----------------|------------------|-----------------|----------------|
| **6** | ~19M | Fast âœ… | Fast âœ… | Good âœ… | **Try first if urgent** |
| **8** | ~24M | Medium âœ… | Medium âœ… | Better âœ… | **RECOMMENDED** â­ |
| **10** | ~30M | Slow | Slow | Better | Consider if depth=8 works |
| **12** | ~35M | Slower | Slower | Best (?) | Current (cÃ³ thá»ƒ overkill) |

**For 32Ã—32 CIFAR-100:**
- **Depth=8 is sweet spot!** â­
- Good balance: speed vs quality
- Proven to work for similar tasks

---

## âœ… SUMMARY:

### **Main Issues:**

1. âŒ **adaLN-Zero init**: Context starts with ZERO effect
2. âš ï¸ **Depth=12**: CÃ³ thá»ƒ overkill cho 32Ã—32 images
3. âš ï¸ **Training time**: ChÆ°a Ä‘á»§ steps cho context fully kick in
4. âš ï¸ **Gradient flow**: 12 layers = slower learning

### **Quick Fix:**

```bash
# RECOMMENDED: Giáº£m depth xuá»‘ng 8
python main_jax.py \
    --depth 8 \              # â† FIX 1: Reduce depth
    --lr 1.5e-4 \            # â† FIX 2: Slightly higher LR
    --hidden_size 384 \
    --hdim 384 \
    --context_channels 384 \
    ... (other args same)
```

**Expected:**
- âœ… Faster training (~25%)
- âœ… Faster context learning (~30%)
- âœ… Better gradient flow
- âœ… Images should show structure by 30k-40k steps

---

## ğŸ¯ FINAL RECOMMENDATION:

**THá»¬ DEPTH=8 TRÆ¯á»šC!** â­

Náº¿u váº«n khÃ´ng work sau 50k steps, thÃ¬ check:
1. Loss curve (should be decreasing)
2. Learning rate (cÃ³ thá»ƒ cáº§n tÄƒng)
3. adaLN initialization (consider warm-start)
4. Pre-train encoder (last resort)

**Good luck!** ğŸš€

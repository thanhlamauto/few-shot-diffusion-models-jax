# FID Computation - Shape Handling Documentation

## üìê Shape Flow Overview

### **Input: CIFAR-100 Images (32√ó32)**

```python
# Generated by DiT model
generated_images: (1024, 3, 32, 32)  # NCHW format (JAX standard)
real_images:      (1024, 3, 32, 32)  # NCHW format

# Value range: [-1, 1] (normalized)
```

---

## üîÑ Shape Transformations

### **Step 1: Transpose to NHWC** (`main_jax.py`)

```python
# Line 360-361 in compute_fid_per_class()
generated_hwc = generated_images.transpose(0, 2, 3, 1)  
# (1024, 3, 32, 32) ‚Üí (1024, 32, 32, 3)

real_hwc = real_images.transpose(0, 2, 3, 1)
# (1024, 3, 32, 32) ‚Üí (1024, 32, 32, 3)
```

**Why NHWC?**
- InceptionV3 in Flax expects **NHWC** format (Height √ó Width √ó Channels)
- Standard for image processing libraries (PIL, OpenCV, TensorFlow)
- Matches pretrained weights format

---

### **Step 2: Resize to 299√ó299** (`fid_jax.py` line 165-167)

```python
# In extract_features_batch()
if batch.shape[1] != 299 or batch.shape[2] != 299:
    batch = jax.image.resize(
        batch, (batch.shape[0], 299, 299, 3), method='bilinear')
    
# (1024, 32, 32, 3) ‚Üí (1024, 299, 299, 3)
```

**Why 299√ó299?**
- **InceptionV3 architecture requirement**
- Original paper: "Rethinking the Inception Architecture" (Szegedy et al., 2015)
- Fixed input size for pretrained weights
- All convolutional layers designed for this specific size

**Resize Method: Bilinear Interpolation**
- Smooth interpolation between pixels
- Standard for upscaling images in FID computation
- Preserves gradients better than nearest-neighbor

---

### **Step 3: Extract Features** (`fid_jax.py` line 169)

```python
batch_features = inception_fn(batch)  
# Input:  (B, 299, 299, 3)
# Output: (B, 1, 1, 2048)  ‚Üê Global pooling output

batch_features = batch_features.reshape(batch_features.shape[0], -1)
# Output: (B, 2048)  ‚Üê Feature vectors
```

---

## ‚ö†Ô∏è Important Considerations

### **1. Upscaling Factor**

```
32√ó32 ‚Üí 299√ó299 = 9.34√ó upscale
```

**Implications:**
- ‚úÖ **Acceptable:** Standard practice in FID computation
- ‚úÖ **Validated:** Used in official FID implementations (e.g., pytorch-fid)
- ‚ö†Ô∏è **Trade-off:** May introduce interpolation artifacts
- ‚ö†Ô∏è **Consistency:** Both real and generated images undergo same transform

**Why It Works:**
- InceptionV3 features are **robust to resolution**
- Global statistics (mean, covariance) capture distribution properties
- Same preprocessing applied to both distributions

---

### **2. Value Range Validation**

```python
# Expected: [-1, 1]
assert -1.1 < images.min() and images.max() < 1.1
```

**Why Important:**
- Pretrained InceptionV3 expects normalized inputs
- Incorrect range ‚Üí Wrong feature statistics ‚Üí Invalid FID score

---

### **3. Format Consistency**

| Stage | Format | Shape | Notes |
|-------|--------|-------|-------|
| DiT Output | NCHW | (N, 3, 32, 32) | JAX standard |
| Pre-FID | NHWC | (N, 32, 32, 3) | Transpose applied |
| InceptionV3 | NHWC | (N, 299, 299, 3) | After resize |
| Features | NF | (N, 2048) | Flatten after pooling |

---

## üß™ Validation & Logging

### **Automatic Checks** (Added in `fid_jax.py`)

```python
# Shape validation
assert real_images.ndim == 4, "Must be 4D (N,H,W,C)"
assert real_images.shape[3] == 3, "Expected 3 channels (RGB)"
assert real_images.shape[1:3] == fake_images.shape[1:3], "Size mismatch"

# Value range warning
if real_min < -1.1 or real_max > 1.1:
    print("‚ö†Ô∏è  Warning: values outside [-1, 1]")

# Resize notification
if original_h != 299 or original_w != 299:
    scale_factor = 299 / max(original_h, original_w)
    print(f"üìè Resizing: {original_h}√ó{original_w} ‚Üí 299√ó299 (scale: {scale_factor:.2f}√ó)")
    
    if scale_factor > 2.0:
        print(f"‚ö†Ô∏è  Warning: Large upscaling ({scale_factor:.1f}√ó)")
```

---

## üìä Expected Console Output

```
Computing per-class FID at step 20000...

======================================================================
Computing Per-Class FID with 1024 samples
======================================================================
üéØ Randomly selected class: 'automobile' (ID: 1)
‚úÖ Loaded 600 images from class 'automobile'

üé® Generating 1024 samples...
Generating samples: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 171/171 [02:15<00:00]

‚úÖ Generated images: (1024, 32, 32, 3)
‚úÖ Real images: (1024, 32, 32, 3)
   Image value range: [-0.99, 0.98]

üîÑ Computing FID score for class 'automobile'...
Extracting features from 1024 real images...
  üìè Resizing images: 32√ó32 ‚Üí 299√ó299 (scale: 9.34√ó)
  ‚ö†Ô∏è  Warning: Large upscaling (9.3√ó) may affect FID accuracy for low-res images
Extracting features from 1024 fake images...
  üìè Resizing images: 32√ó32 ‚Üí 299√ó299 (scale: 9.34√ó)
Computing statistics...
Computing FID score...
‚úÖ FID Score: 45.23 (Class: automobile)
======================================================================
```

---

## üîç Debugging Shape Issues

### **Common Errors & Fixes**

#### **Error 1: Shape Mismatch**
```python
AssertionError: real_images must be 4D (N,H,W,C), got shape (1024, 3, 32, 32)
```
**Fix:** Need to transpose NCHW ‚Üí NHWC
```python
images = images.transpose(0, 2, 3, 1)
```

#### **Error 2: Wrong Channel Count**
```python
AssertionError: Expected 3 channels (RGB), got 1
```
**Fix:** Image is grayscale, need to convert to RGB or repeat channels

#### **Error 3: Out of Range Values**
```python
Warning: values outside [-1, 1]: [0.00, 255.00]
```
**Fix:** Need to normalize
```python
images = (images / 127.5) - 1.0  # [0, 255] ‚Üí [-1, 1]
```

---

## üìö References

1. **InceptionV3 Paper:** "Rethinking the Inception Architecture for Computer Vision"
   - Szegedy et al., CVPR 2016
   - Input size: 299√ó299√ó3

2. **FID Paper:** "GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium"
   - Heusel et al., NeurIPS 2017
   - Uses InceptionV3 features for distribution comparison

3. **Standard Implementations:**
   - pytorch-fid: https://github.com/mseitzer/pytorch-fid
   - tensorflow-gan: https://github.com/tensorflow/gan
   - All use 299√ó299 resize for InceptionV3

---

## ‚úÖ Summary

| Component | Expected Shape | Notes |
|-----------|---------------|-------|
| **DiT Output** | (N, 3, H, W) | NCHW format |
| **Transpose** | (N, H, W, 3) | NHWC format |
| **Resize** | (N, 299, 299, 3) | InceptionV3 input |
| **Features** | (N, 2048) | After global pooling |

**Key Points:**
- ‚úÖ Shape transformations are **automatic**
- ‚úÖ Validation checks **catch errors early**
- ‚úÖ Logging shows **what's happening**
- ‚úÖ Consistent with **standard FID implementations**

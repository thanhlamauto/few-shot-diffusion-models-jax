# Kiá»ƒm Tra 3 Potential Issues

## âœ… Issue 1: Data Augmentation

### **Code: `dataset/base.py`, `__getitem__()`**

```python
def __getitem__(self, item, lbl=None):
    """
    Returns:
        samples: np.array, shape (ns, nc, size, size)
        (Optionally) targets: np.array, shape (ns,) - class labels
    """
    # Create a set
    samples = self.data['inputs'][item]
    samples = rescale(samples, val_range=(-1, 1), orig_range=(0, 1))
    
    # KHÃ”NG CÃ“ AUGMENTATION! âœ…
    
    if lbl is not None:
        targets = self.data['targets'][item]
        return samples, targets
    else:
        return samples
```

**âœ… Káº¿t luáº­n: KHÃ”NG CÃ“ augmentation nÃ o lÃ m thay Ä‘á»•i class!**
- Chá»‰ cÃ³ `rescale` tá»« [0,1] â†’ [-1,1] (normalize)
- KhÃ´ng cÃ³ random crop, flip, rotation, color jitter, etc.

---

## âœ… Issue 2: Shuffle trong DataLoader

### **Code: `dataset/__init__.py`, `create_loader()`**

```python
def create_loader(args, split, shuffle, drop_last=False):
    dataset = select_dataset(args, split)
    bs = args.batch_size
    if split in ["vis", "val", "test"]:
        bs = args.batch_size_eval
    
    loader = data.DataLoader(
        dataset=dataset,
        batch_size=bs,
        shuffle=shuffle,       # â† Shuffle ÄÃ‚Y!
        num_workers=0,
        drop_last=drop_last,
    )
```

**ğŸ” PhÃ¢n tÃ­ch:**

### **Shuffle hoáº¡t Ä‘á»™ng nhÆ° tháº¿ nÃ o?**

`DataLoader` vá»›i `shuffle=True`:
1. Shuffle **index cá»§a sets**, KHÃ”NG shuffle images TRONG set
2. Dataset tráº£ vá»: `samples[item]` vá»›i shape `(ns, C, H, W)`
3. DataLoader collate: `(bs, ns, C, H, W)`

**VÃ­ dá»¥:**
```
Dataset cÃ³ 100 sets:
- Set 0: [img0, img1, img2, img3, img4] tá»« class 5
- Set 1: [img5, img6, img7, img8, img9] tá»« class 12
- ...
- Set 99: [img495, img496, img497, img498, img499] tá»« class 3

Shuffle=True:
- Chá»n random order: [Set 42, Set 7, Set 91, ...]
- NhÆ°ng images TRONG má»—i set VáºªN GIá»® NGUYÃŠN THá»¨ Tá»°!

Batch:
- batch_set shape: (bs, ns, C, H, W)
- batch_set[0] = Set 42 (nguyÃªn xi) âœ…
- batch_set[1] = Set 7 (nguyÃªn xi) âœ…
```

**âœ… Káº¿t luáº­n: Shuffle KHÃ”NG áº£nh hÆ°á»Ÿng Ä‘áº¿n structure cá»§a set!**
- Shuffle chá»‰ thay Ä‘á»•i thá»© tá»± GIá»®A cÃ¡c sets
- KHÃ”NG shuffle images TRONG set
- â†’ Context-target matching váº«n Ä‘Ãºng! âœ…

---

## âš ï¸ Issue 3: Multi-device (pmap) Splitting

### **Code: `main_jax.py`, training loop**

```python
# Line 494-500:
p_train_step = jax.pmap(
    train_step_fn, axis_name="batch", donate_argnums=(0, 1)
)

n_devices = jax.local_device_count()
logger.log(f"Found {n_devices} JAX devices")
```

```python
# Line 531-545:
for batch in pbar:
    # batch shape: (bs, ns, C, H, W) from DataLoader
    
    global_step += 1
    
    # Prepare batch
    batch_jax = jnp.array(batch)  # Convert to JAX array
    
    # Split batch across devices for pmap
    # CRITICAL: How is batch split?
```

### **ğŸ” PhÃ¢n tÃ­ch pmap splitting:**

**Giáº£ sá»­:**
- `batch_size = 32` (from DataLoader)
- `n_devices = 4` (TPU/GPU)
- `batch_jax` shape: `(32, 5, 3, 32, 32)`

**pmap sáº½ split nhÆ° tháº¿ nÃ o?**

```python
# pmap automatically splits along axis 0:
# Device 0: batch[0:8]   = sets 0-7
# Device 1: batch[8:16]  = sets 8-15
# Device 2: batch[16:24] = sets 16-23
# Device 3: batch[24:32] = sets 24-31
```

**Trong má»—i device:**
```python
# Device 0 receives:
batch_device0 = batch_jax[0:8]  # (8, 5, 3, 32, 32)

# Call train_step_fn:
train_step_fn(p_state, batch_device0, rng_device0)
  â†“
vfsddpm_loss(..., batch_device0, ...)
  â†“
leave_one_out_c(..., batch_device0, ...)
  # batch_device0[0] = Set 0 (intact) âœ…
  # batch_device0[1] = Set 1 (intact) âœ…
  # ...
  # batch_device0[7] = Set 7 (intact) âœ…
```

**âœ… Key Point:**
- pmap splits **GIá»®A cÃ¡c sets** (axis 0)
- KHÃ”NG split **TRONG set** (axis 1)
- Má»—i device nháº­n má»™t sá»‘ sets NGUYÃŠN Váº¸N
- â†’ Context-target matching VáºªN ÄÃšNG trÃªn má»i device! âœ…

---

## ğŸ¯ FINAL VERIFICATION:

### **Trace Complete Flow:**

```
1. Dataset (base.py):
   make_sets() â†’ Sets vá»›i images tá»« cÃ¹ng class
   â†“
   __getitem__() â†’ Tráº£ vá» set (ns, C, H, W)
   âœ… NO augmentation

2. DataLoader (__init__.py):
   Shuffle sets (khÃ´ng shuffle TRONG set)
   â†“
   Batch: (bs, ns, C, H, W)
   âœ… Set structure preserved

3. pmap (main_jax.py):
   Split batch across devices GIá»®A cÃ¡c sets
   â†“
   Each device: (bs/n_devices, ns, C, H, W)
   âœ… Each set intact

4. leave_one_out_c (vfsddpm_jax.py):
   For each image i in set:
     Support = other images in SAME set
   â†“
   c[i] = context from images {0,...,i-1,i+1,...,ns-1}
   âœ… Same class

5. Training (gaussian_diffusion_jax.py):
   x_flat[i] + c_flat[i]
   âœ… Correct matching!
```

---

## âœ…âœ…âœ… Káº¾T LUáº¬N CUá»I CÃ™NG:

**Cáº¢ 3 ISSUES Äá»€U á»”N:**

1. âœ… **No harmful augmentation** - Chá»‰ cÃ³ rescale
2. âœ… **Shuffle preserves sets** - Chá»‰ shuffle giá»¯a sets, khÃ´ng trong set
3. âœ… **pmap splits correctly** - Split giá»¯a sets, khÃ´ng trong set

**â†’ TARGET IMAGE LUÃ”N NHáº¬N ÄÃšNG CONTEXT Tá»ª CLASS Cá»¦A NÃ“!** ğŸ‰

---

## ğŸ”¬ ThÃªm: CÃ¡ch Test Thá»±c Táº¿

Náº¿u muá»‘n cháº¯c cháº¯n hÆ¡n, cÃ³ thá»ƒ thÃªm logging trong training loop:

```python
# In main_jax.py, inside train_step_fn:
if global_step % 1000 == 0:
    # Log first batch
    batch_np = np.array(batch_set)
    # Verify all images in batch_np[0] are from same class
    # by checking pixel statistics or saving to disk
```

Hoáº·c check trong wandb logs:
- `train/support_target_set_*` visualizations
- Verify visually that support and target are from same class

---

## ğŸ“Š TÃ³m Táº¯t:

| Check | Status | Reason |
|-------|--------|--------|
| **Data augmentation** | âœ… Safe | No class-changing augmentation |
| **DataLoader shuffle** | âœ… Safe | Shuffles sets, not images within sets |
| **pmap splitting** | âœ… Safe | Splits between sets, not within sets |
| **Overall** | âœ…âœ…âœ… | **Target receives correct context!** |

**Codebase ÄÃšNG, khÃ´ng cÃ³ bug trong context-target matching!** ğŸ¯

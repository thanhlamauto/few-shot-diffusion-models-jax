# üìä W&B Metrics - C√¥ng th·ª©c v√† Gi·∫£i th√≠ch

T√†i li·ªáu n√†y m√¥ t·∫£ chi ti·∫øt c√°c metrics ƒë∆∞·ª£c log l√™n Weights & Biases trong qu√° tr√¨nh training VFSDDPM-JAX.

---

## üéØ Core Training Metrics

### 1. **loss** (T·ªïng Loss)
**V·ªã tr√≠:** `model/vfsddpm_jax.py` (d√≤ng 331-335)

**C√¥ng th·ª©c:**

**Ch·∫ø ƒë·ªô Deterministic:**
```
loss = mean_flat(diffusion_loss).mean()
```

**Ch·∫ø ƒë·ªô Variational:**
```
loss = mean_flat(diffusion_loss).mean() + KL_divergence
```

**√ù nghƒ©a:**
- Metric ch√≠nh ƒë·ªÉ ƒëo training progress
- Gi·∫£m ‚Üí model ƒëang h·ªçc t·ªët
- Bao g·ªìm reconstruction loss v√† regularization (n·∫øu variational)

**Code:**
```python
total = mean_flat(losses["loss"]).mean()
if klc is not None:
    total = total + klc
losses["loss"] = total
```

---

### 2. **mse** (Mean Squared Error)
**V·ªã tr√≠:** ƒê∆∞·ª£c t√≠nh b·ªüi `GaussianDiffusion.training_losses()`

**C√¥ng th·ª©c:**
```
mse = (1 / (B √ó C √ó H √ó W)) √ó Œ£(Œµ_Œ∏(x_t, t, c) - Œµ)¬≤
```

Trong ƒë√≥:
- `x_t` = noisy image t·∫°i timestep t
- `t` = random timestep ‚àà [0, T]
- `c` = conditioning vector t·ª´ leave-one-out encoding
- `Œµ_Œ∏` = predicted noise b·ªüi DiT model
- `Œµ ~ N(0, I)` = true noise ƒë√£ ƒë∆∞·ª£c th√™m v√†o
- `B` = batch size, `C` = channels, `H` = height, `W` = width

**√ù nghƒ©a:**
- ƒêo ƒë·ªô ch√≠nh x√°c c·ªßa noise prediction
- Gi·∫£m ‚Üí model d·ª± ƒëo√°n noise t·ªët h∆°n ‚Üí sample quality t·ªët h∆°n

**Qu√° tr√¨nh t√≠nh:**
1. Sample timestep: `t ~ Uniform(0, T)`
2. Add noise: `x_t = ‚àö(·æ±_t) √ó x_0 + ‚àö(1-·æ±_t) √ó Œµ`
3. Predict: `Œµ_pred = model(x_t, t, c)`
4. Compute MSE: `mse = mean((Œµ_pred - Œµ)¬≤)`

---

### 3. **context** (Conditioning Vector)
**V·ªã tr√≠:** `model/vfsddpm_jax.py` - `leave_one_out_c()` (d√≤ng 250-294)

**C√¥ng th·ª©c:**

**Deterministic Mode:**
```
c_i = Encoder({x_1, ..., x_n} \ {x_i})
```

**Variational Mode:**
```
h = Encoder({x_1, ..., x_n} \ {x_i})
Œº, log(œÉ¬≤) = Posterior(h)
c_i = Œº + œÉ √ó Œµ,  where Œµ ~ N(0, 1)
```

**Chi ti·∫øt:**
- **Input:** Set of images `{x_1, ..., x_n}` (th∆∞·ªùng n=6)
- **Leave-one-out:** ƒê·ªÉ predict x_i, d√πng {x_1,...,x_n}\{x_i} l√†m context
- **Encoder:** ViT ho·∫∑c sViT (Set Transformer)
- **Output shape:** 
  - FiLM mode: `(B√ón, hdim)`
  - LAG mode: `(B√ón, 1, hdim)` (1 token)

**Code:**
```python
for i in range(ns):
    idx = [k for k in range(ns) if k != i]
    x_subset = batch_set[:, idx]  # (b, ns-1, C, H, W)
    hc = encode_set(params["encoder"], enc, x_subset, cfg, train=train)
    c_vec, klc = sample_context(rngs[i], hc, cfg, posterior, params_post)
    c_list.append(c_vec[:, None, ...])
```

---

### 4. **klc** (KL Divergence - Variational Mode Only)
**V·ªã tr√≠:** `model/vfsddpm_jax.py` - `gaussian_kl()` (d√≤ng 108-119)

**C√¥ng th·ª©c:**
```
KL(q(z|x) || p(z)) = 0.5 √ó Œ£[
    œÉ¬≤_q / œÉ¬≤_p 
    + (Œº_q - Œº_p)¬≤ / œÉ¬≤_p 
    - 1 
    + log(œÉ¬≤_p / œÉ¬≤_q)
]
```

**V·ªõi prior p = N(0, I):**
```
KL(q || p) = 0.5 √ó Œ£[œÉ¬≤_q + Œº¬≤_q - 1 - log(œÉ¬≤_q)]
```

**Chuy·ªÉn sang bits:**
```
klc = mean(KL) / log(2)
```

**√ù nghƒ©a:**
- Regularization term cho variational posterior
- ƒêo "kho·∫£ng c√°ch" gi·ªØa learned distribution v√† prior
- Qu√° cao ‚Üí posterior collapse (ko h·ªçc ƒë∆∞·ª£c g√¨)
- Qu√° th·∫•p ‚Üí under-regularized

**Code:**
```python
def gaussian_kl(qm: Array, qlogvar: Array, pm: Array, plogvar: Array) -> Array:
    qv = jnp.exp(qlogvar)
    pv = jnp.exp(plogvar)
    return 0.5 * (
        (qv / pv)
        + ((qm - pm) ** 2) / pv
        - 1.0
        + (plogvar - qlogvar)
    )
```

---

### 5. **eval_loss** (Validation Loss)
**V·ªã tr√≠:** `main_jax.py` - `eval_loop()` (d√≤ng 140-162)

**C√¥ng th·ª©c:**
```
eval_loss = (1/N) √ó Œ£ vfsddpm_loss(batch_i, train=False)
```

**√ù nghƒ©a:**
- ƒê√°nh gi√° generalization tr√™n validation set
- D√πng EMA parameters (kh√¥ng ph·∫£i training params)
- `train=False` ‚Üí kh√¥ng dropout, batch norm eval mode

**Code:**
```python
params_eval = flax.jax_utils.unreplicate(p_state.ema_params)
for _ in range(num_batches):
    loss_dict = vfsddpm_loss(
        jax.random.PRNGKey(0), params_eval, modules, 
        batch_np, cfg, train=False
    )
    losses.append(np.array(loss_dict["loss"]))
return float(np.mean(losses))
```

---

## üî¨ Debug & Monitoring Metrics

### 6. **debug/context_norm** (L2 Norm)
**V·ªã tr√≠:** `model/set_diffusion/train_util_jax.py` (d√≤ng 229)

**C√¥ng th·ª©c:**
```
||c||‚ÇÇ = ‚àö(Œ£·µ¢ c¬≤·µ¢)
```

**√ù nghƒ©a:**
- ƒêo magnitude t·ªïng th·ªÉ c·ªßa context vector
- Qu√° l·ªõn ‚Üí potential numerical instability
- Qu√° nh·ªè ‚Üí context kh√¥ng ch·ª©a ƒë·ªß information

**Code:**
```python
metrics["debug/context_norm"] = jnp.linalg.norm(context)
```

---

### 7. **debug/context_mean** (Mean Absolute Value)
**C√¥ng th·ª©c:**
```
mean(|c|) = (1/D) √ó Œ£·µ¢ |c·µ¢|
```
Trong ƒë√≥ D = dimension c·ªßa context vector

**√ù nghƒ©a:**
- Average magnitude c·ªßa context features
- Useful ƒë·ªÉ detect feature collapse

---

### 8. **debug/context_max** (Max Absolute Value)
**C√¥ng th·ª©c:**
```
max(|c|) = max·µ¢ |c·µ¢|
```

**√ù nghƒ©a:**
- Ph√°t hi·ªán outlier values trong context
- Qu√° l·ªõn ‚Üí c√≥ feature dominate

---

### 9. **debug/context_std** (Standard Deviation)
**C√¥ng th·ª©c:**
```
œÉ_c = ‚àö[(1/D) √ó Œ£·µ¢ (c·µ¢ - Œº_c)¬≤]
```

**√ù nghƒ©a:**
- ƒêo diversity c·ªßa context features
- Qu√° th·∫•p ‚Üí features uniform (bad)
- Healthy range: 0.1 - 1.0

**Code:**
```python
metrics["debug/context_std"] = jnp.std(context)
```

---

### 10. **debug/grad_norm_encoder** & **debug/grad_norm_dit**
**V·ªã tr√≠:** `model/set_diffusion/train_util_jax.py` (d√≤ng 235-245)

**C√¥ng th·ª©c:**
```
||‚àáŒ∏||‚ÇÇ = ‚àö[Œ£_all_layers Œ£_all_params (‚àÇL/‚àÇŒ∏·µ¢)¬≤]
```

**Chi ti·∫øt t√≠nh to√°n:**
```python
flat_grads = jax.tree_util.tree_leaves(grad_tree)
grad_norm = sqrt(sum(sum(g¬≤) for g in flat_grads))
```

**√ù nghƒ©a:**
- Monitor training stability
- Gradient explosion: grad_norm > 100
- Gradient vanishing: grad_norm < 1e-6
- Healthy range: 0.1 - 10.0

**H√†nh ƒë·ªông:**
- N·∫øu explode ‚Üí gi·∫£m learning rate ho·∫∑c th√™m gradient clipping
- N·∫øu vanish ‚Üí tƒÉng learning rate ho·∫∑c check architecture

---

### 11. **debug/param_norm_encoder** & **debug/param_norm_dit**
**C√¥ng th·ª©c:**
```
||Œ∏||‚ÇÇ = ‚àö[Œ£_all_layers Œ£_all_params Œ∏¬≤·µ¢]
```

**√ù nghƒ©a:**
- Theo d√µi weight magnitude qua training
- TƒÉng li√™n t·ª•c ‚Üí potential weight drift
- Useful ƒë·ªÉ so s√°nh v·ªõi grad_norm:
  ```
  relative_grad = grad_norm / param_norm
  ```

**Code:**
```python
flat_params = jax.tree_util.tree_leaves(param_tree)
param_norm = jnp.sqrt(sum(jnp.sum(p**2) for p in flat_params))
metrics[f"debug/param_norm_{key}"] = param_norm
```

---

## üìà Evaluation Metrics

### 12. **fid** (Fr√©chet Inception Distance)
**V·ªã tr√≠:** `main_jax.py` - `compute_fid_per_class()` (d√≤ng 212-414)

**C√¥ng th·ª©c:**
```
FID = ||Œº_real - Œº_gen||¬≤ + Tr(Œ£_real + Œ£_gen - 2‚àö(Œ£_real Œ£_gen))
```

**Chi ti·∫øt:**
1. Extract features t·ª´ InceptionV3 (pool_3 layer):
   ```
   f_real = InceptionV3(x_real)  # (N, 2048)
   f_gen = InceptionV3(x_gen)    # (N, 2048)
   ```

2. Compute statistics:
   ```
   Œº_real = mean(f_real, axis=0)
   Œº_gen = mean(f_gen, axis=0)
   Œ£_real = cov(f_real)
   Œ£_gen = cov(f_gen)
   ```

3. Compute FID:
   ```
   diff = Œº_real - Œº_gen
   covmean = sqrtm(Œ£_real @ Œ£_gen)
   FID = diff.T @ diff + trace(Œ£_real + Œ£_gen - 2√ócovmean)
   ```

**√ù nghƒ©a:**
- **Lower is better** (0 = perfect match)
- FID < 10: Excellent quality
- FID 10-30: Good quality
- FID 30-50: Acceptable
- FID > 50: Poor quality

**L∆∞u √Ω:**
- T√≠nh per-class (random 1 class m·ªói l·∫ßn eval)
- Default: 1024 samples per class
- C·∫ßn √≠t nh·∫•t 600 samples ƒë·ªÉ FID stable

---

## üé® Visualization Metrics (W&B Images)

### 13. **train/support_target_set_{i}**
- Hi·ªÉn th·ªã leave-one-out split trong training
- Target (red border) vs Support (blue border)
- Logged m·ªói `log_interval` steps

### 14. **generation/set_{i}**
- Support images (top row)
- Generated samples (bottom row)
- Logged m·ªói `save_interval` steps

### 15. **fid_eval/example_{i}**
- Support set (blue border)
- Generated images (green border)
- Real images (red border)
- Logged khi compute FID

---

## üìä Step-by-step Training Process

### Forward Pass:
```
1. Batch: (B, ns, C, H, W) in [-1, 1]
2. For each image i in set:
   a. support = set \ {image_i}
   b. c_i = Encoder(support)
   c. If variational: c_i = Œº + œÉ√óŒµ
3. Flatten: x = (B√óns, C, H, W)
4. Sample t ~ Uniform(0, T)
5. Add noise: x_t = ‚àö·æ±_t √ó x + ‚àö(1-·æ±_t) √ó Œµ
6. Predict: Œµ_pred = DiT(x_t, t, c)
7. Loss: MSE(Œµ_pred, Œµ) + KL (if variational)
```

### Backward Pass:
```
1. Compute gradients: ‚àáŒ∏ L
2. Update params: Œ∏ ‚Üê Œ∏ - lr √ó ‚àáŒ∏
3. Update EMA: Œ∏_ema ‚Üê Œ≤ √ó Œ∏_ema + (1-Œ≤) √ó Œ∏
4. Log metrics to W&B
```

### Sampling (DDIM):
```
1. Start: x_T ~ N(0, I)
2. For t = T, T-1, ..., 1:
   a. Œµ_Œ∏ = DiT(x_t, t, c)
   b. xÃÇ_0 = (x_t - ‚àö(1-·æ±_t) √ó Œµ_Œ∏) / ‚àö·æ±_t
   c. œÉ_t = Œ∑ √ó ‚àö((1-Œ±_t)/(1-·æ±_t)) √ó ‚àö(1-·æ±_t/·æ±_{t-1})
   d. x_{t-1} = ‚àö·æ±_{t-1} √ó xÃÇ_0 + ‚àö(1-·æ±_{t-1}-œÉ¬≤_t) √ó Œµ_Œ∏ + œÉ_t √ó Œµ
3. Return: x_0
```

---

## üéØ Typical Value Ranges

| Metric | Initial | Mid-Training | Well-Trained |
|--------|---------|--------------|--------------|
| **loss** | 0.08-0.15 | 0.03-0.05 | 0.02-0.035 |
| **mse** | 0.08-0.15 | 0.03-0.05 | 0.02-0.035 |
| **klc** | 5-20 bits | 1-5 bits | 0.5-2 bits |
| **eval_loss** | Similar to loss | Track with loss | < loss (good generalization) |
| **context_norm** | 50-150 | 60-120 | 60-80 |
| **context_std** | 0.5-1.2 | 0.6-1.0 | 0.6-0.8 |
| **grad_norm** | 0.5-5.0 | 0.1-2.0 | 0.05-0.5 |
| **fid** | N/A | 40-80 | 10-30 |

---

## ‚ö†Ô∏è Warning Signs

### Training Instability:
- ‚ùå **Loss spikes:** Sudden jumps in loss ‚Üí learning rate too high
- ‚ùå **grad_norm > 100:** Gradient explosion ‚Üí add gradient clipping
- ‚ùå **context_norm exploding:** Encoder instability ‚Üí check normalization
- ‚ùå **eval_loss >> loss:** Overfitting ‚Üí need regularization

### Poor Convergence:
- ‚ùå **Loss plateau early:** Stuck in local minimum ‚Üí increase model capacity
- ‚ùå **FID not improving:** Sample quality issue ‚Üí check conditioning
- ‚ùå **klc ‚Üí 0:** Posterior collapse ‚Üí adjust KL weight

### Debugging Tips:
1. **Compare grad_norm vs param_norm:**
   ```python
   relative_grad = grad_norm / param_norm
   # Healthy: 1e-4 to 1e-2
   ```

2. **Monitor context statistics:**
   ```python
   # Should have diversity
   context_std > 0.5
   # Should not dominate
   context_max / context_mean < 5
   ```

3. **Check eval_loss vs loss gap:**
   ```python
   # Generalization gap
   gap = eval_loss - loss
   # Healthy: gap < 0.01
   # Overfitting: gap > 0.02
   ```

---

## üìù Logging Configuration

### Log Intervals:
- **Training metrics:** Every `log_interval` steps (default: 100)
- **Evaluation:** Every `save_interval` steps (default: 20,000)
- **FID:** Same as evaluation (expensive)
- **Checkpoints:** Same as evaluation

### W&B Settings:
```python
wandb.init(
    project="fsdm-jax",
    name=args.wandb_run_name,
    config=vars(args),
)

# Log training metrics
wandb.log({
    "loss": loss,
    "mse": mse,
    "debug/grad_norm_dit": grad_norm,
    # ... other metrics
}, step=global_step)

# Log images
wandb.log({
    "train/support_target_set_0": wandb.Image(fig),
    "generation/set_0": wandb.Image(fig),
}, step=global_step)
```

---

## üîç References

### Code Locations:
1. **Main training loop:** `main_jax.py` lines 524-815
2. **Loss computation:** `model/vfsddpm_jax.py` - `vfsddpm_loss()`
3. **Training step:** `model/set_diffusion/train_util_jax.py` - `train_step_pmap()`
4. **FID computation:** `metrics/fid_jax.py` - `compute_fid()`
5. **Sampling:** `model/set_diffusion/gaussian_diffusion_jax.py` - `ddim_sample_loop()`

### Key Papers:
1. **DDPM:** Denoising Diffusion Probabilistic Models (Ho et al., 2020)
2. **DiT:** Scalable Diffusion Models with Transformers (Peebles & Xie, 2023)
3. **FID:** GANs Trained by a Two Time-Scale Update Rule (Heusel et al., 2017)

---

**Generated:** 2025-12-10  
**Model:** VFSDDPM-JAX (DiT backbone)  
**Framework:** JAX/Flax with pmap parallelization
